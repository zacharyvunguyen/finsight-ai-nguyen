# FinSight AI - Document Processing & Analysis

An intelligent Streamlit application for processing, analyzing, and querying PDF documents using advanced AI capabilities.

## ğŸŒŸ Features

- PDF document upload with duplicate detection to Google Cloud Storage
- Secure document handling with authenticated access only
- Structured (tables) and unstructured (text) data extraction using LlamaParse
- Vector embeddings generation and storage with Pinecone
- Context-aware document querying using LangChain and LlamaIndex
- Retrieval Augmented Generation (RAG) pipeline for intelligent document chat
- Interactive chat interface with source attribution
- Production-ready deployment on Google Cloud Platform
- Enhanced name recognition for queries about specific individuals
- Modern, responsive UI with compact information display

## ğŸ”§ Tech Stack

- **Frontend**: Streamlit
- **Storage**: Google Cloud Storage (Project: finsight-ai-nguyen)
- **Document Processing**: LlamaParse
- **Embeddings**: OpenAI (text-embedding-3-small)
- **Vector Storage**: Pinecone
- **Language Model**: GPT-3.5 Turbo
- **Query Engine**: LangChain
- **Deployment**: Google Cloud Run & App Engine

## ğŸ“ Project Structure

finsight-ai-nguyen/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ streamlit/
â”‚   â”‚   â”œâ”€â”€ app.py          # Streamlit application
â”‚   â”‚   â””â”€â”€ README.md       # Streamlit app documentation
â”‚   â”œâ”€â”€ main.py             # Main application entry point
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ gcs.py          # GCS operations
â”‚   â”‚   â”œâ”€â”€ parser.py       # PDF parsing
â”‚   â”‚   â”œâ”€â”€ embeddings.py   # Vector operations
â”‚   â”‚   â””â”€â”€ chatbot.py      # LangChain integration
â”‚   â””â”€â”€ components/         # Streamlit components
â”œâ”€â”€ config/
â”‚   â””â”€â”€ keys/              # GCP credentials
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Original PDFs
â”‚   â”œâ”€â”€ processed/        # Processed data
â”‚   â”œâ”€â”€ temp/             # Temporary files
â”‚   â””â”€â”€ test/            # Test files
â”œâ”€â”€ scripts/             # Setup and utility scripts
â”‚   â”œâ”€â”€ setup.py         # Unified setup script
â”‚   â”œâ”€â”€ setup/           # Setup modules
â”‚   â”‚   â”œâ”€â”€ setup_gcp.py     # GCP setup
â”‚   â”‚   â”œâ”€â”€ setup_pinecone.py # Pinecone setup
â”‚   â”‚   â””â”€â”€ setup_rag_pipeline.py # RAG pipeline setup
â”‚   â””â”€â”€ utils/           # Utility functions
â”‚       â””â”€â”€ common.py    # Common utility functions
â”œâ”€â”€ tests/               # Unit tests
â”‚   â”œâ”€â”€ test_llamaparse_pdf.py # LlamaParse PDF test
â”‚   â”œâ”€â”€ test_gcs_pdf.py  # GCS PDF test
â”‚   â”œâ”€â”€ test_rag_with_openai.py # RAG with OpenAI test
â”‚   â”œâ”€â”€ STREAMLIT_APP.md # Streamlit app documentation
â”‚   â””â”€â”€ README.md        # Test suite documentation
â”œâ”€â”€ deployment/         # Deployment configs
â”œâ”€â”€ .env               # Environment variables
â””â”€â”€ requirements.txt   # Python dependencies

## ğŸš€ Quick Start

See [QUICKSTART.md](QUICKSTART.md) for detailed setup and running instructions.

## ğŸ“‹ Prerequisites

- Python 3.9+ with Anaconda
- Google Cloud Platform account (Project: finsight-ai-nguyen)
- OpenAI API key
- Pinecone API key
- LlamaParse API key

## ğŸ”’ Security Features

- All documents are stored securely in Google Cloud Storage
- No public links are generated for uploaded documents
- Access to documents requires GCP authentication
- Duplicate detection prevents redundant storage
- Metadata is stored securely in Firestore

## ğŸ¤– RAG Pipeline

The application uses a Retrieval Augmented Generation (RAG) pipeline to provide intelligent responses to queries about your documents:

1. **Document Processing**: PDFs are processed using LlamaParse to extract structured text
2. **Chunking**: Documents are split into semantic chunks for better retrieval
3. **Embedding**: Text chunks are converted to vector embeddings using OpenAI
4. **Storage**: Embeddings are stored in Pinecone with namespaces to avoid duplication
5. **Retrieval**: When a query is made, the most relevant chunks are retrieved
6. **Generation**: GPT-3.5 Turbo generates responses based on the retrieved context
7. **Source Attribution**: Responses include references to the source material

## ğŸ“± Streamlit Application

The project includes a Streamlit application for interacting with the RAG pipeline:

- **Document Selection**: Choose which documents to query
- **Natural Language Interface**: Ask questions in plain English
- **Source Attribution**: See exactly where information comes from
- **Modern UI**: Clean, responsive design with intuitive navigation
- **Enhanced Entity Recognition**: Improved handling of queries about specific individuals

For detailed information about the Streamlit application, see [tests/STREAMLIT_APP.md](tests/STREAMLIT_APP.md).

## ğŸ† Milestones

- **v0.1.0** - Initial project setup
- **v0.2.0** - PDF upload functionality with GCS integration
- **v0.3.0** - Secure document handling with authenticated access only
- **v0.4.0** - RAG pipeline integration with chat interface (CURRENT)
- **v0.4.1** - Enhanced UI with modern design and improved UX
- **v0.4.2** - Advanced entity recognition and improved query handling

## ğŸ“ License

MIT License
